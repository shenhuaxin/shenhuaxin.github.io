[ { "title": "java 调用 python", "url": "/posts/py4j/", "categories": "java", "tags": "java, python", "date": "2025-06-12 00:00:00 +0000", "snippet": "需求最近碰到 “需要在 java 中执行 python 代码片段” 的需求。调研了几种方案。Jython 、Py4j 、jep 、pemja最后选取了 Py4j 方案。实现方案java端开发在 springboot 启动时，创建 GatewayServer，然后将和 python 交互的类保存下来。@Slf4j@Componentpublic class Py4jServer implements ApplicationListener&amp;lt;ApplicationStartedEvent&amp;gt; { @Override public void onApplicationEvent(ApplicationStartedEvent event) { try { GatewayServer server = new GatewayServer(); server.start(); PyEntrypoint pyEntrypoint = (PyEntrypoint) server.getPythonServerEntryPoint(new Class[]{PyEntrypoint.class}); FlowHelper.pyEntrypoint = pyEntrypoint; } catch (Exception e) { log.error(e.getMessage(), e); } }}public interface PyEntrypoint { String execute(String code, String globalParams, String localParams, String globalParamsDefine); String shutdown();}python开发import jsonimport threadingimport timefrom py4j.java_gateway import JavaGateway, GatewayParameters, CallbackServerParametersclass PyEntrypoint(object): gateway_ref:JavaGateway = None class Java: implements = [&quot;com.demo.PyEntrypoint&quot;] def execute(self, code, global_params, local_params, global_params_define): try: print(&quot;接受请求：&quot; + global_params) gp = json.loads(global_params) lp = json.loads(local_params) gpd = json.loads(global_params_define) exec(code, gp, lp) del[gp[&#39;__builtins__&#39;]] for key in lp.keys(): if key in gpd: gp[key] = lp[key] data = json.dumps(gp) print(&quot;返回数据：&quot; + data) return data except Exception as e: print(e) def shutdown(self): try: print(time.time()) # asyncio.create_task(_shutdown()) thread = threading.Thread(target=self._shutdown_0) thread.start() print(time.time()) return &quot;success&quot; except Exception as e: print(e) def _shutdown_0(self): try: time.sleep(3) print(time.time().__str__() + &quot;关闭&quot;) self.gateway_ref.shutdown() except Exception as e: print(e)try: pe = PyEntrypoint() gateway_param = GatewayParameters() gateway = JavaGateway( gateway_parameters=gateway_param, callback_server_parameters=CallbackServerParameters(), python_server_entry_point=pe, ) print(&quot;==== 启动 ====&quot;) print(gateway) pe.gateway_ref = gateway print(&quot;==== 启动 ====&quot;)except Exception as e: print(e)启动python进程若是服务器无法下载第三方包，只能通过离线安装第三方包1、创建python虚拟环境python3 -m venv venvsource venv/bin/activatepip3 install py4j-0.10.9.9-py2.py3-none-any.whlpython3 PyEntrypoint.py如果需要后台启动，则使用 nohup 命令 nohup python3 -u PyEntrypoint.py &amp;gt; rule.log 2&amp;gt;&amp;amp;1 &amp;amp;如果需要使用脚本的话#!/bin/bashsource venv/bin/activatenohup python3 -u PyEntrypoint.py &amp;gt; rule.log 2&amp;gt;&amp;amp;1 &amp;amp;" }, { "title": "arthas生成火焰图优化性能", "url": "/posts/arthas-profiler/", "categories": "java", "tags": "java, arthas", "date": "2025-03-12 00:00:00 +0000", "snippet": "需求最近碰到一个集合循环，程序执行偏慢的场景，需要进行排查。代码案例 public static void main(String[] args) throws InterruptedException { String data = FileUtil.readString(&quot;/Users/test/Downloads/测试.json&quot;, Charset.defaultCharset()); JSONObject bigObj = JSONUtil.parseObj(data); for (int i = 0; ; i++) { String dataStr = JSONUtil.toJsonStr(bigObj); log.info(&quot;dataStr:{}&quot;, dataStr); } }arthas处理1、使用 arthas 的 profiler profiler start等待程序执行，执行完之后生成火焰图 profiler stop –format flamegraph可以看到hutool 的 json 工具耗时是最长的，然后就可以排查业务逻辑慢的具体原因。经过排查，hutool的json序列化比fastjson慢了很多，后续替换为fastjson" }, { "title": "docker https 接口访问不通", "url": "/posts/docker-mtu/", "categories": "docker", "tags": "docker, https", "date": "2023-02-13 00:00:00 +0000", "snippet": "问题在容器中访问 https 接口不通，但是宿主机上访问是通的。通过 curl -v 再次访问，发现是握手失败。经过查阅，发现是 docker 的 mtu 设置的问题，在宿主机上的 mtu 为 1450， 但是在容器中是 1500。如果docker的网卡mtu大于宿主机的网卡mtu，在大数据包传输时可能会丢失数据。这也是造成了通信到一半就中断的原因。解决方法： 在 daemon.json 中设置 mtu { &quot;mtu&quot;: 1450} 注： 如果有 live-restore: true 那么可能导致 docker 容器未重启，那么 docker0 的 mtu 一直未能变更，删除改配置后有效。 " }, { "title": "使用 git module 集成前后端项目", "url": "/posts/gitmodule/", "categories": "git", "tags": "git", "date": "2023-01-12 00:00:00 +0000", "snippet": "需求最近有个项目需要在流水线中集成前后端项目一起部署使用流水线部署时，怎么同时拉取前后端项目，避免本地打包前端项目放到后端项目中。解决研究后发现使用 gitmodules 特别好处理这个问题。在后端项目中，使用以下命令将前端项目添加进后端项目的子模块中。 git submodule add https://codeup.aliyun.com/xxxx.git xxxx本地也会生成一个 .gitmodules 文件，可以在该文件中添加 branch = dev ，设置子模块的分支。[submodule &quot;xxxx&quot;] path = xxxx url = https://codeup.aliyun.com/xxxx.git branch = dev也可以使用以下命令设置分支 git config -f .gitmodules submodule.xxxx.branch dev后续后续发现在流水线使用 sh 命令更加方便。 git clone https://codeup.aliyun.com/xxxx.git 还可以增加一个 . 号，让拉取的代码直接放在当前文件夹git clone https://codeup.aliyun.com/xxxx.git ." }, { "title": "记录一次Java应用Hang住的问题", "url": "/posts/java-hang/", "categories": "java", "tags": "java, mysql", "date": "2022-05-28 00:00:00 +0000", "snippet": "问题运维新建了一个灰度集群，当他们在部署第一个应用时，应用启动后Hang住，无法向下执行。日志也不再打印。当时将几个远端的连接地址给telnet过，发现都正常。而且CPU使用率低。这时候就使用到了 jstack 命令，打印java线程执行情况。我们可以看到 main 线程还是 RUNNABLE 状态，当时第一时间也没怀疑是 MySQL 的问题，毕竟 telnet MySQL 时，网络是通的。但是我也找不到其他的问题。就将 jar 放到了其他的服务器上进行执行。发现是正常运行。这啥时候就开始怀疑新的集群机器有问题了。再结合上 jstack 中的日志。开始怀疑可能是 MySQL 的网络问题。然后就加上了jdbcUrl中加入 connectionTimout 的配置，但是应用还是 hang 住。再加上了 socketTimeout , 启动后就报错了。这时候找到 DBA ，DBA发现新的机器的IP和以前的机器IP不处于同一个网段。然后新增了白名单设置。应用就正常启动了。注为什么没加白名单， MySQL 的 TCP 连接能够建立起来？ 为啥呢？回答： vpc链路没加白名单能telnet能通是正常的，服务端拦截的是第三个tcp握手包，telnet发出这个包判断成功，实际上后续的包都发不过来了，mysql业务层是连不上的" }, { "title": "记录一次SpringBoot启动脚本命令行参数失效的问题", "url": "/posts/apollo/", "categories": "springboot", "tags": "springboot, apollo", "date": "2022-05-27 00:00:00 +0000", "snippet": "启动脚本命令行参数失效在一次应用发布的过程中，运维表示 –server.port=8080未生效，监听到的端口并不是8080，导致健康检测失败，应用不断重启。这时候就感觉很奇怪了，因为在SpringBoot中，命令行参数的优先级应该是最高的。在继续找问题的时候，发现我们使用的配置中心Apollo中设置了 server.port=8138 这个配置。所以怀疑是否是Apollo将 SpringBoot 的配置进行了覆盖。在 debug 启动应用后，我们可以看到 Apollo 的配置优先级最高。这就说明了 Apollo 做了一些扩展。Apollo 在下面两个地方进行了扩展。 ApolloApplicationContextInitializer PropertySourcesProcessor在 ApolloApplicationContextInitializer 中将 Apollo 的配置的优先级设置为最高。PropertySourcesProcessor 也有类似的操作，不过 PropertySourcesProcessor 是为了给非SpringBoot应用设置的。解决方法那么Apollo的优先级最高，如何在启动脚本中设置能够设置参数覆盖Apollo的配置呢。方法是 -D 参数。 比如设置 -Dserver.port=8080 就能覆盖 Apollo 的配置。我们可以看到在 Apollo 的 DefaultConfig 中， 是先获取 Java 应用的属性配置和环境变量。再去获取Apollo的配置。注不光 Apollo 会做这样的事情，SpringCloudConfig 也会做相同的事情，但是 SpringCloudConfig 有参数可以设置不覆盖Java系统参数，这样就会将配置中心的配置放到 SystemEnvironment 之后。这样优先级就会降低。" }, { "title": "记录一次K8S Pod OOM的问题", "url": "/posts/pod-oom/", "categories": "java", "tags": "java, k8s", "date": "2022-05-13 00:00:00 +0000", "snippet": "问题在一次测试环境的容器部署中， 运维将Pod的内存限制设置为512M，同时 JVM 的 -Xmx 也为 512M。运行一段时间后 pod 就被OOM kill， 重复这种行为几次后， 我们就意识到了不对。运维调整内存为 1G, 然后就不在报错了，但是这并不是我们预期的行为。 而且在正常运行的情况下，JVM的堆内存也就在 200M 左右，而且应该也不会达到500M。之前在虚拟机上，设置的 -Xmx 也是 512M。 这说明还有别的东西在吃内存。直到运维给我发了这张图，看到这个命令，我就去以前的机器上执行了相同的命令，占用内存也比设置的 -Xmx， 在700M左右。这说明我没重视的非堆内存，占用了200M+的内存空间。这比我想象的要多很多。然后就是用 Jcmd 命令查看了非堆内存占用的具体大小。发现是不到300M。 这样的话，我们的问题就解决了。Pod 的内存限制，需要减去大概 300M ， 才能做为 -Xmx 的数值。注：" }, { "title": "Windows Terminal连接堡垒机", "url": "/posts/window-terminal/", "categories": "软件", "tags": "工作效率", "date": "2022-05-01 00:00:00 +0000", "snippet": "windows terminal 现在足够的好看，做为一个终端进行使用。自定义自己的默认终端打开json文件，设置 defaultProfile 的值为自己想用的终端guid。作为SSH工具使用 首先确保安装了 open ssh 客户端。 使用 ssh 连接远程服务器 open ssh 是交互式的连接，所以需要自己输入密码，那么如果想不输入密码，那么我们就需要一些自动化工具帮忙。在 windows 中没有一些其他在 linux 中好用的工具，有一个 go 语言编写的 expect 工具 + lua 脚本可以帮助我们进行一些自动化的操作。在登录的时候，脚本就会帮助我们输入密码，免去了我们一步操作。lua脚本如下所示：echo(true)if spawn([[ssh]],&quot;shen@ubuntu01.com&quot;) then expect(&quot;password:&quot;) echo(false) send(&quot;shen\\r&quot;) expect(&quot;~]$&quot;) echo(true) send(&quot;exit\\r&quot;)end连接堡垒机连接堡垒机有点特殊，不知为何用 powershell 使用 ssh 连接堡垒机，就会报错。所以使用了 Git Bash 连接堡垒机。或许以后 powershell 就可以了，就不用这么麻烦了。使用 gitbash 连接堡垒机命令如下 D:\\programefile\\Git\\bin\\bash.exe -c “ssh 188xxx260@139.xxx.xxx.2 -p60022”windows terminal 和 lua脚本如下所示：参考 go expect" }, { "title": "Eureka源码04-Eureka 抓取注册表流程", "url": "/posts/eureka-fetch/", "categories": "Eureka源码", "tags": "eureka", "date": "2022-03-29 00:00:00 +0000", "snippet": "在 DiscoveryClient 中有一段抓取服务注册表的代码， 当时没有深入， 现在继续看看。 if (clientConfig.shouldFetchRegistry() &amp;amp;&amp;amp; !fetchRegistry(false)) { fetchRegistryFromBackup(); }如果需要抓取注册表， 那么就进行一次注册表的抓取， 抓取失败了， 从备用的地址中继续抓取。深入看下 fetchRegistry 函数干了什么？ private boolean fetchRegistry(boolean forceFullRegistryFetch) { // 拉取注册表 Stopwatch tracer = FETCH_REGISTRY_TIMER.start(); try { Applications applications = getApplications(); if (clientConfig.shouldDisableDelta() || (!Strings.isNullOrEmpty(clientConfig.getRegistryRefreshSingleVipAddress())) || forceFullRegistryFetch || (applications == null) || (applications.getRegisteredApplications().size() == 0) || (applications.getVersion() == -1)) //Client application does not have latest library supporting delta { // 拉取全量注册表 getAndStoreFullRegistry(); } else { // 增量更新 getAndUpdateDelta(applications); } // 设置一致性hash值 applications.setAppsHashCode(applications.getReconcileHashCode()); logTotalInstances(); } finally { if (tracer != null) { tracer.stop(); } } // Notify about cache refresh before updating the instance remote status onCacheRefreshed(); // Update remote status based on refreshed data held in the cache updateInstanceRemoteStatus(); // registry was fetched successfully, so return true return true; } 先从本地获取一下 Applications 缓存， 如果本地有， 进行一次增量的注册表更新 如果本地没有， 进行一次全量的注册表拉取。 计算 applications 的 一致性 hash code。全量抓取注册表， 调用的是 /apps 的请求 ， 对应了 ApplicationsResource.getContainers 方法， 删掉一些不重要的函数，代码如下 public Response getContainers(@PathParam(&quot;version&quot;) String version, @HeaderParam(HEADER_ACCEPT) String acceptHeader, @HeaderParam(HEADER_ACCEPT_ENCODING) String acceptEncoding, @HeaderParam(EurekaAccept.HTTP_X_EUREKA_ACCEPT) String eurekaAccept, @Context UriInfo uriInfo, @Nullable @QueryParam(&quot;regions&quot;) String regionsStr) { // 缓存key Key cacheKey = new Key(Key.EntityType.Application, ResponseCacheImpl.ALL_APPS, keyType, CurrentRequestVersion.get(), EurekaAccept.fromString(eurekaAccept), regions ); Response response; if (acceptEncoding != null &amp;amp;&amp;amp; acceptEncoding.contains(HEADER_GZIP_VALUE)) { response = Response.ok(responseCache.getGZIP(cacheKey)) .header(HEADER_CONTENT_ENCODING, HEADER_GZIP_VALUE) .header(HEADER_CONTENT_TYPE, returnMediaType) .build(); } else { response = Response.ok(responseCache.get(cacheKey)) .build(); } return response; }发现 是从 responseCache 中取出 ALL_APPS 的数据。然后把数据缓存到 Eureka Client本地。" }, { "title": "Eureka源码03-Eureka服务注册流程", "url": "/posts/eureka-register/", "categories": "Eureka源码", "tags": "eureka", "date": "2022-03-27 00:00:00 +0000", "snippet": "eureka server 接受 eureka client 服务注册的请求， 在 eureka-core 项 com/netflix/eureka/resources 包下。有一个 ApplicationsResource 类。 @Path(&quot;{appId}&quot;) public ApplicationResource getApplicationResource( @PathParam(&quot;version&quot;) String version, @PathParam(&quot;appId&quot;) String appId) { CurrentRequestVersion.set(Version.toEnum(version)); // 没有加资源指示器， 是一个子资源定位器 return new ApplicationResource(appId, serverConfig, registry); }将 {appId} 请求路径下的所有 Http 请求， 都交给 ApplicationResource 这个类去处理。而服务注册就在下面这段代码中。public Response addInstance(InstanceInfo info, @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) { registry.register(info, &quot;true&quot;.equals(isReplication)); return Response.status(204).build(); // 204 to be backwards compatible } public void register(final InstanceInfo info, final boolean isReplication) { int leaseDuration = Lease.DEFAULT_DURATION_IN_SECS; if (info.getLeaseInfo() != null &amp;amp;&amp;amp; info.getLeaseInfo().getDurationInSecs() &amp;gt; 0) { leaseDuration = info.getLeaseInfo().getDurationInSecs(); } super.register(info, leaseDuration, isReplication); replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication); } 调用服务的注册方法 将注册信息同步到其他的 Eureka Server 上。我们再来看看父类中的 register 函数。 public void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) { try { read.lock(); // 通过服务名称拿到服务的实例Map Map&amp;lt;String, Lease&amp;lt;InstanceInfo&amp;gt;&amp;gt; gMap = registry.get(registrant.getAppName()); REGISTER.increment(isReplication); if (gMap == null) { final ConcurrentHashMap&amp;lt;String, Lease&amp;lt;InstanceInfo&amp;gt;&amp;gt; gNewMap = new ConcurrentHashMap&amp;lt;String, Lease&amp;lt;InstanceInfo&amp;gt;&amp;gt;(); gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap); if (gMap == null) { gMap = gNewMap; } } Lease&amp;lt;InstanceInfo&amp;gt; existingLease = gMap.get(registrant.getId()); Lease&amp;lt;InstanceInfo&amp;gt; lease = new Lease&amp;lt;InstanceInfo&amp;gt;(registrant, leaseDuration); // 加入到服务注册表中 gMap.put(registrant.getId(), lease); // 保存最近注册服务的队列 synchronized (recentRegisteredQueue) { recentRegisteredQueue.add(new Pair&amp;lt;Long, String&amp;gt;( System.currentTimeMillis(), registrant.getAppName() + &quot;(&quot; + registrant.getId() + &quot;)&quot;)); } // If the lease is registered with UP status, set lease service up timestamp if (InstanceStatus.UP.equals(registrant.getStatus())) { lease.serviceUp(); } registrant.setActionType(ActionType.ADDED); recentlyChangedQueue.add(new RecentlyChangedItem(lease)); registrant.setLastUpdatedTimestamp(); // 主动过期掉 readwriteMap中 对应的 服务的信息 和 ALL_APPS invalidateCache(registrant.getAppName(), registrant.getVIPAddress(), registrant.getSecureVipAddress()); } finally { read.unlock(); } } 往注册表中添加这个新的实例 更新新的期望心跳值和心跳阈值 主动过期掉 读写缓存 中对应的一些数据" }, { "title": "Eureka源码02-EurekaHttpClient装饰模式的使用", "url": "/posts/eureka-httpclient/", "categories": "Eureka源码", "tags": "eureka", "date": "2022-03-21 00:00:00 +0000", "snippet": "1. EurekaTransportEurekaTransport 持有了用于 http 通讯的组件，用于向 eureka server 发送服务注册等信息的有 registrationClient，用于向 eureka server查询服务信息的有 queryClient。bootstrapResolver 这个是用于对 service-url.defaultZone 这个配置或者其他的 zone 进行解析。 private static final class EurekaTransport { private ClosableResolver bootstrapResolver; private TransportClientFactory transportClientFactory; private EurekaHttpClient registrationClient; private EurekaHttpClientFactory registrationClientFactory; private EurekaHttpClient queryClient; private EurekaHttpClientFactory queryClientFactory; }2. ClosableResolverClosableResolver 的实现类为 ConfigClusterResolver，在 getClusterEndpoints -&amp;gt; getClusterEndpointsFromConfig -&amp;gt; EndpointUtils.getServiceUrlsMapFromConfig-&amp;gt; EurekaClientConfig.getEurekaServerServiceUrls 从配置文件中获取到了 eureka 集群信息。 public List&amp;lt;String&amp;gt; getEurekaServerServiceUrls(String myZone) { String serviceUrls = configInstance.getStringProperty( namespace + CONFIG_EUREKA_SERVER_SERVICE_URL_PREFIX + &quot;.&quot; + myZone, null).get(); if (serviceUrls == null || serviceUrls.isEmpty()) { serviceUrls = configInstance.getStringProperty( namespace + CONFIG_EUREKA_SERVER_SERVICE_URL_PREFIX + &quot;.default&quot;, null).get(); } if (serviceUrls != null) { return Arrays.asList(serviceUrls.split(&quot;,&quot;)); } return new ArrayList&amp;lt;String&amp;gt;(); }3. registrationClient如果registration.enabled = true则需要向 eureka server 进行注册，那么就会创建 registrationClient。 if (clientConfig.shouldRegisterWithEureka()) { EurekaHttpClientFactory newRegistrationClientFactory = null; EurekaHttpClient newRegistrationClient = null; try { newRegistrationClientFactory = EurekaHttpClients.registrationClientFactory( eurekaTransport.bootstrapResolver, eurekaTransport.transportClientFactory, transportConfig ); newRegistrationClient = newRegistrationClientFactory.newClient(); } catch (Exception e) { logger.warn(&quot;Transport initialization failure&quot;, e); } eurekaTransport.registrationClientFactory = newRegistrationClientFactory; eurekaTransport.registrationClient = newRegistrationClient; }newRegistrationClientFactory 用于创建 newRegistrationClient。 static EurekaHttpClientFactory canonicalClientFactory(final String name, final EurekaTransportConfig transportConfig, final ClusterResolver&amp;lt;EurekaEndpoint&amp;gt; clusterResolver, final TransportClientFactory transportClientFactory) { return new EurekaHttpClientFactory() { @Override public EurekaHttpClient newClient() { return new SessionedEurekaHttpClient( name, RetryableEurekaHttpClient.createFactory( name, transportConfig, clusterResolver, RedirectingEurekaHttpClient.createFactory(transportClientFactory), ServerStatusEvaluators.legacyEvaluator()), transportConfig.getSessionedClientReconnectIntervalSeconds() * 1000 ); } @Override public void shutdown() { wrapClosable(clusterResolver).shutdown(); } }; }我们可以看到当调用 factory.newClient 函数时，最终创建的是一个 SessionedEurekaHttpClient。至于 RetryableEurekaHttpClient 和RedirectingEurekaHttpClient 则是在执行 execute 函数时创建的。现在我们看到了三种代理的 EurekaHttpClient，但是 MetricsCollectingEurekaHttpClient 是在哪里创建的呢？在创建 RedirectingEurekaHttpClient 的时候，最终会使用到 eurekaTransport.transportClientFactory，也就是 Jersey1TransportClientFactories。 public TransportClientFactory newTransportClientFactory(final Collection&amp;lt;ClientFilter&amp;gt; additionalFilters, final EurekaJerseyClient providedJerseyClient) { ApacheHttpClient4 apacheHttpClient = providedJerseyClient.getClient(); if (additionalFilters != null) { for (ClientFilter filter : additionalFilters) { if (filter != null) { apacheHttpClient.addFilter(filter); } } } final TransportClientFactory jerseyFactory = new JerseyEurekaHttpClientFactory(providedJerseyClient, false); final TransportClientFactory metricsFactory = MetricsCollectingEurekaHttpClient.createFactory(jerseyFactory); return new TransportClientFactory() { @Override public EurekaHttpClient newClient(EurekaEndpoint serviceUrl) { return metricsFactory.newClient(serviceUrl); } @Override public void shutdown() { metricsFactory.shutdown(); jerseyFactory.shutdown(); } }; }至此，我们可以得到 EurekaHttpClient 的调用顺序，SessionedEurekaHttpClient -&amp;gt; RetryableEurekaHttpClient -&amp;gt; RedirectingEurekaHttpClient-&amp;gt; MetricsCollectingEurekaHttpClient -&amp;gt; JerseyApplicationClient4. EurekaHttpClientDecorator就以从实现 EurekaHttpClient 接口的 register 函数举例，将 register 的行为下放到了实现类。在子类中，当调用 RequestExecutor#execute 时，会委托给代理进行 register，这样的话装饰器可以在实际调用函数前后做一些装饰操作。 protected abstract &amp;lt;R&amp;gt; EurekaHttpResponse&amp;lt;R&amp;gt; execute(RequestExecutor&amp;lt;R&amp;gt; requestExecutor); @Override public EurekaHttpResponse&amp;lt;Void&amp;gt; register(final InstanceInfo info) { return execute(new RequestExecutor&amp;lt;Void&amp;gt;() { @Override public EurekaHttpResponse&amp;lt;Void&amp;gt; execute(EurekaHttpClient delegate) { return delegate.register(info); } @Override public RequestType getRequestType() { return RequestType.Register; } }); }5. EurekaHttpClientDecorator实现类的作用 MetricsCollectingEurekaHttpClient： 对不同的请求结果进行统计。 RedirectingEurekaHttpClient：在创建 client 的时候，会进行一次请求，如果返回结果需要进行重定向，就会根据重新重定向地址重新生成一个client RetryableEurekaHttpClient：如果请求失败，则会换一个 eureka server 进行重试 SessionedEurekaHttpClient： 超过一定时间没有使用过这个 client，就会重新创建一个新的 client。防止一直使用相同的 client。" }, { "title": "记录一次SQL超时问题", "url": "/posts/error-transacation/", "categories": "mysql", "tags": "mysql", "date": "2022-03-21 00:00:00 +0000", "snippet": "1. 背景最近，在迁移某个环境，遇到了一次SQL超时问题，记录一下。2. 现象开始我们遇到的情况如图所示，显示一个 update sql 因为超时而被取消了，但是这是一条根据主键更新的SQL, 按道理来说不会很慢，所以猜测是不是在这个事务中，有其他耗时长的 sql 或者是因为这条记录被锁住了。3.分析后续在对不同的数据进行相似操作时发现，第一次操作会报 NoClassDefFoundError ，后续进行 update 都超时。这时候就判断是否是事务未提交。但是更新后的数据却能够在页面上查询的到。但是数据库中查询不到。然后使用 SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS; 对锁信息进行查询， 发现确实出现了锁等待的情况。这时候猜测应该是事务未提交，所以第一次占有行锁未释放，第二次获取行锁失败，所以导致超时，代码经过简化后如图：我们看到这里使用的是手动控制事务，并且 rollback 是在 catch(Exception) 代码块中，而之前报的错是一个 Error ，所以导致的是事务未进行提交。而后续的操作则因为获取不到锁而失败。 @Transactional 注解默认会回滚 RuntimeException 和 Error那么为什么事务未提交，却能在页面上查询到更新后的数据呢，这是因为数据库连接池中默认只有一条连接，所以能查到之前未提交的数据。" }, { "title": "Eureka源码01-EurekaServer初始化", "url": "/posts/eureka-server-init/", "categories": "Eureka源码", "tags": "eureka", "date": "2022-03-19 00:00:00 +0000", "snippet": "1. 源码首先我们看下 eureka 源码的模块。archaius 是配置管理组件，jersey 是类似于 springmvc 的 web 框架，governator 是一些实验性的代码。在这些模块中，eureka-core、eureka-client、eureka-server 是三个重要的模块。2. eureka server 初始化在 eureka-server 中，主要就是一个 web.xml，在这里面有一个 listener 和五个 filter。listener 是会随着 web 服务器的启动而启动，所以EurekaBootStrap 就是 eureka 服务端的入口。五个 filter 是对一些请求的拦截。 &amp;lt;listener&amp;gt; &amp;lt;listener-class&amp;gt;com.netflix.eureka.EurekaBootStrap&amp;lt;/listener-class&amp;gt; &amp;lt;/listener&amp;gt; 下面就是 EurekaBootStrap 在web容器启动时被调用的函数。初始化了 eureka 环境 和 eureka server 上下文。 public void contextInitialized(ServletContextEvent event) { try { // 初始化eureka环境， datacenter和environment 没有配置，设置默认值 initEurekaEnvironment(); // 初始化eureka server上下文 initEurekaServerContext(); ServletContext sc = event.getServletContext(); sc.setAttribute(EurekaServerContext.class.getName(), serverContext); } catch (Throwable e) { logger.error(&quot;Cannot bootstrap eureka server :&quot;, e); throw new RuntimeException(&quot;Cannot bootstrap eureka server :&quot;, e); } } initEurekaEnvironment 中初始化 eureka 环境，这里使用到了 archaius ，并没有什么重要的东西，只是对用户覆盖的一些配置进行设置。 protected void initEurekaEnvironment() throws Exception { logger.info(&quot;Setting the eureka configuration..&quot;); String dataCenter = ConfigurationManager.getConfigInstance().getString(EUREKA_DATACENTER); if (dataCenter == null) { logger.info(&quot;Eureka data center value eureka.datacenter is not set, defaulting to default&quot;); ConfigurationManager.getConfigInstance().setProperty(ARCHAIUS_DEPLOYMENT_DATACENTER, DEFAULT); } else { ConfigurationManager.getConfigInstance().setProperty(ARCHAIUS_DEPLOYMENT_DATACENTER, dataCenter); } String environment = ConfigurationManager.getConfigInstance().getString(EUREKA_ENVIRONMENT); if (environment == null) { ConfigurationManager.getConfigInstance().setProperty(ARCHAIUS_DEPLOYMENT_ENVIRONMENT, TEST); logger.info(&quot;Eureka environment value eureka.environment is not set, defaulting to test&quot;); } } initEurekaServerContext 是一个重要的函数，在这里面进行了 eureka 服务的启动。 创建 EurekaServerConfig，加载eureka-server.properties 创建一个 eureka client，用于集群之间的同步 创建一个 PeerAwareInstanceRegistry，用于感知 eureka 集群的服务实例注册表 PeerAwareInstanceRegistry 创建一个 PeerEurekaNodes，代表 eureka 集群中的其他节点 创建一个 EurekaServerContext, 代表了 eureka server 上下文。 通过 eureka 集群注册表 registry 从其他 eureka server 节点获取服务注册信息 注册 eureka monitor 3. 创建 eurekaServerConfig在创建 eurekaServerConfig 时，会从 eureka-server.properties 中读取配置项。ConfigurationManager 会读取配置信息，后面也是从ConfigurationManager 中获取配置信息。 private void init() { String env = ConfigurationManager.getConfigInstance().getString( EUREKA_ENVIRONMENT, TEST); ConfigurationManager.getConfigInstance().setProperty( ARCHAIUS_DEPLOYMENT_ENVIRONMENT, env); String eurekaPropsFile = EUREKA_PROPS_FILE.get(); try { // 读取 配置文件中的配置项。 ConfigurationManager .loadCascadedPropertiesFromResources(eurekaPropsFile); } catch (IOException e) { } }4. 创建 eureka client首先创建了一个 EurekaInstanceConfig，读取 eureka-client.properties，第二步根据 instanceConfig 创建一个 InstanceInfo 用于代表当前的 eureka server。需要注意的是，在集群模式下， 一个 eureka server 也是一个 eureka client。最后，创建一个 DiscoveryClient， // eureka-client.properties创建EurekaInstanceConfig EurekaInstanceConfig instanceConfig = isCloud(ConfigurationManager.getDeploymentContext()) ? new CloudInstanceConfig() : new MyDataCenterInstanceConfig(); // 基于instanceConfig创建InstanceInfo, 根据instanceConfig和InstanceInfo创建ApplicationInfoManager applicationInfoManager = new ApplicationInfoManager( instanceConfig, new EurekaConfigBasedInstanceInfoProvider(instanceConfig).get()); EurekaClientConfig eurekaClientConfig = new DefaultEurekaClientConfig(); // 创建EurekaClient eurekaClient = new DiscoveryClient(applicationInfoManager, eurekaClientConfig);4.1. 创建 DiscoveryClient创建 DiscoveryClient走的是下面这个构造函数，在这个构造函数中，做了很多事情。DiscoveryClient#DiscoveryClient(ApplicationInfoManager, EurekaClientConfig, AbstractDiscoveryClientOptionalArgs, Provider&amp;lt;BackupRegistry&amp;gt;)下面就来看看主要做的几件事。 创建一个支持调度的线程池，scheduler 创建一个用于心跳定时任务的调度器，cacheRefreshExecutor 创建一个用于缓存刷新任务的调度器，heartbeatExecutor 创建一个 eureka 用于网络传输组件 从其他 eureka server 中拉取注册表 初始化定时任务，这里有三个任务，缓存刷新任务，定时心跳任务。使用 scheduler调度心跳和缓存刷新的定时任务的定时执行，用各自的executor用于执行任务。并且会向其他 eureka server 进行注册 try { // default size of 2 - 1 each for heartbeat and cacheRefresh // 支持调度的线程池 scheduler = Executors.newScheduledThreadPool(2, new ThreadFactoryBuilder() .setNameFormat(&quot;DiscoveryClient-%d&quot;) .setDaemon(true) .build()); // 支持心跳的线程池 heartbeatExecutor = new ThreadPoolExecutor( 1, clientConfig.getHeartbeatExecutorThreadPoolSize(), 0, TimeUnit.SECONDS, new SynchronousQueue&amp;lt;Runnable&amp;gt;(), new ThreadFactoryBuilder() .setNameFormat(&quot;DiscoveryClient-HeartbeatExecutor-%d&quot;) .setDaemon(true) .build() ); // use direct handoff // 支持缓存刷新的线程池 cacheRefreshExecutor = new ThreadPoolExecutor( 1, clientConfig.getCacheRefreshExecutorThreadPoolSize(), 0, TimeUnit.SECONDS, new SynchronousQueue&amp;lt;Runnable&amp;gt;(), new ThreadFactoryBuilder() .setNameFormat(&quot;DiscoveryClient-CacheRefreshExecutor-%d&quot;) .setDaemon(true) .build() ); // use direct handoff // EurekaTransport, 初始化eureka网络传输组件 eurekaTransport = new EurekaTransport(); scheduleServerEndpointTask(eurekaTransport, args); } catch (Throwable e) { } // 拉取注册表信息，如果没有成功， 从备用的注册表地址中拉取 if (clientConfig.shouldFetchRegistry() &amp;amp;&amp;amp; !fetchRegistry(false)) { fetchRegistryFromBackup(); } // call and execute the pre registration handler before all background tasks (inc registration) is started if (this.preRegistrationHandler != null) { this.preRegistrationHandler.beforeRegistration(); } // 初始化调度任务 initScheduledTasks();5. 创建服务注册表 registry根据 eurekaServerConfig、eurekaClientConfig、eurekaClient 创建了 PeerAwareInstanceRegistry。 registry = new PeerAwareInstanceRegistryImpl( eurekaServerConfig, eurekaClient.getEurekaClientConfig(), serverCodecs, eurekaClient );6. 创建 PeerEurekaNodespeerEurekaNodes 代表了 eureka server 集群中的其他节点，使用到了 registry、applicationInfoManager。 PeerEurekaNodes peerEurekaNodes = getPeerEurekaNodes( registry, eurekaServerConfig, eurekaClient.getEurekaClientConfig(), serverCodecs, applicationInfoManager );7. 创建 serverContext 并初始化这里最重要的就是 serverContext.initialize() 这行代码。 首先根据配置的 serviceUrl 创建 PeerEurekaNode 集合，并且创建一个10分钟更新一次集群节点的定时任务。然后会创建一个15分钟更新一次心跳阈值的定时任务。 serverContext = new DefaultEurekaServerContext( eurekaServerConfig, serverCodecs, registry, peerEurekaNodes, applicationInfoManager ); // ServerContext的Holder， 用于持有serverContext，后面好拿出来使用。 EurekaServerContextHolder.initialize(serverContext); serverContext.initialize();8. 初始化服务注册表从其他 eureka 节点中获取客户端实例，并且添加到注册表中。然后将自身的状态设置为 UP，开始接收外部的服务请求。在 web.xml 中的 StatusFilter，使用到了这个状态，只有 eureka server 状态为 UP 时，才会对请求进行放行。否则返回服务还未准备好，请尝试其他的 server 节点。 // 同步实例信息 int registryCount = registry.syncUp(); // 开放注册 registry.openForTraffic(applicationInfoManager, registryCount);9. 注册 eureka 监控器 EurekaMonitors.registerAllStats();10. 小结在 eureka server 启动的时候， 创建了 eureka client 用于获取获取其他 eureka server 中的信息和将自身注册到其他的 eureka server 中。创建了注册表 registry 用于存储服务实例。创建了定时任务，用于集群间的有清除缓存任务、发送心跳任务、更新集群节点任务。用于处理客户端的更新心跳阈值定时任务。还有两个概念需要注意。Applications 代表了注册到 eureka server 中的所有服务，Application 代表的是某一个服务，InstanceInfo 代表的是某一个服务下的一个实例节点。还有就是 eureka client 中用来 http 通讯的 EurekaHttpClient，使用了装饰器模式，对 jersey 进行了各种装饰。有指标统计、重试、重定向、定时重建session这四个。" }, { "title": "Java单元测试实践", "url": "/posts/unit-test/", "categories": "单元测试", "tags": "spock", "date": "2022-03-18 00:00:00 +0000", "snippet": "1. 背景单元测试的收益 单元测试能更快地发现问题 单元测试的性价比很高，因为发现错误越晚，修复的代价越高 有助于源码的优化，可以放心进行重构单元测试的痛点 单元测试浪费了太多的时间，写单元测试的时间比写代码的时间还长 代码逻辑过于复杂，单元测试很难写 部分项目主要和数据库交互，造数据复杂测试金字塔2. SpockSpock 是一个 Java 和 Groovy 应用程序的测试框架。Spock 结合 Groovy 动态语言的特点，提供了各种标签，并采用简单、通用、结构化的描述语言让编写测试代码更加简洁、高效。Junit 单纯用于测试，不提供 Mock 功能。Mockito 虽然可以把接口等依赖屏蔽掉，但是他们之间需要整合，语法繁琐。Spock 自带 Mock 功能，使用简单方便，并且提供了规范化的描述，定义了多种标签（given、when、then、where 等），去描述代码 ”应该做什么“，“输入条件是什么”，“输出是否符合预期”，从语义层面规范代码的编写。再加上 Groovy 动态语言的强大语法，能写出简洁的测试代码。3. 内存数据库H2H2 非常适合在测试程序中使用，程序关闭时自动清理数据，H2 数据库表结构和表数据可以通过spring.datasource进行指定。单元测试中使用非常地简单，仅需要修改 jdbc 连接即可。引入依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;com.h2database&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;h2&amp;lt;/artifactId&amp;gt; &amp;lt;scope&amp;gt;test&amp;lt;/scope&amp;gt; &amp;lt;/dependency&amp;gt;数据源连接spring.datasource.druid.url=jdbc:h2:mem:goods;INIT=CREATE SCHEMA IF NOT EXISTS goods\\\\;SET SCHEMA goodsspring.datasource.druid.driver-class-name=org.h2.Driverspring.datasource.username=saspring.datasource.password=# 开启控制台需要启动webspring.h2.console.enabled=truespring.h2.console.path=/h2数据初始化spring.datasource.schema=classpath:schema.sqlspring.datasource.data=classpath:data.sqlspring.datasource.initialization-mode=always 某些 MySQL 语法对于H2来说是不支持的。初始化 H2 的 Schema 最好能给每个 not null 字段都加上默认值。4. 数据层单元测试框架 DbUnitDbUnit 基于 xml 优雅地构造测试数据集，例如：&amp;lt;?xml version=&#39;1.0&#39; encoding=&#39;UTF-8&#39;?&amp;gt;&amp;lt;dataset&amp;gt; &amp;lt;user id=&quot;1&quot; username=&quot;test-user1&quot; password=&quot;test-user1&quot; name=&quot;test-user1&quot;/&amp;gt; &amp;lt;user id=&quot;2&quot; username=&quot;test-user2&quot; password=&quot;test-user2&quot; name=&quot;test-user2&quot;/&amp;gt;&amp;lt;/dataset&amp;gt;user代表表名，后面的键值对为列名和对应的值。但是通过xml构造数据集还是太麻烦，加入对于 Spock 扩展的处理框架，使用注解的方式构造测试数据集。@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.METHOD)@ExtensionAnnotation(DbunitExtension)@interface Dbunit { /** * &amp;lt;pre&amp;gt; * @Dbunit(content = { * t_goods_price_discount(goods_attr_id: 1, tenancy_threshold: 1, price_discount: 10) * t_goods_price_discount(goods_attr_id: 2, tenancy_threshold: 2, price_discount: 20) * T_GOODS_PRICE (goods_attr_id: 1, start_date: &#39;2022-03-18&#39;, end_date: &#39;2022-03-25&#39;, price: 10, km_price: 20, min_days: 4) * }) * &amp;lt;/pre&amp;gt; */ Class&amp;lt;? extends Closure&amp;gt; content() default Closure.class; String schema() default &quot;&quot;;}5. 单元测试覆盖率在pom文件里引用Jacoco的插件：jacoco-maven-plugin，然后执行mvn package 命令，成功后会在target目录下生成单元测试覆盖率的报告，点开报告找到对应的被测试类查看覆盖情况。6. Groovy在单元测试相比于Java的优势 在单元测试环节，可以对一些访问控制权限进行放开，例如，构造函数中指定字段名和字段值的方式创建对象，更加的方便、简洁。参考 Spock单元测试框架介绍以及在美团优选的实践 有赞单元测试实践 老K的Java博客-Spock系列 @Dbunit注解的实现1 @Dbunit注解的实现2" }, { "title": "值得收藏的软件", "url": "/posts/good-soft/", "categories": "软件", "tags": "工作效率", "date": "2022-03-02 00:00:00 +0000", "snippet": "软件列表 功能 Windows UML Astah professional 流程图 processon 阅读 EPUB 电子书 Neat Reader 文本比对 Beyond Compare windows壁纸 动态主题（微软商店） windows工具集 powerToys windows显示器亮度调节 Twinkle Tray zsh zsh 、oh my zsh (自动补全、语法高亮)、tmux git Sourcetree " }, { "title": "Git", "url": "/posts/git/", "categories": "Git", "tags": "git", "date": "2022-01-10 00:00:00 +0000", "snippet": "常用命令 功能 命令 添加文件/更改到暂存区 git add filename 添加所有文件/更改到暂存区 git add . 提交 git commit -m msg 从远程仓库拉取最新代码 git pull origin master 推送到远程仓库 git push origin master 查看配置信息 git config –list 查看文件列表 git ls-files 比较工作区和暂存区 git diff 比较暂存区和版本库 git diff –cached 比较工作区和版本库 git diff HEAD 从暂存区移除文件 git reset HEAD filename 查看本地远程仓库配置 git remote -v 回滚 git reset –hard 提交SHA 强制推送到远程仓库 git push -f origin master 修改上次 commit git commit –amend 推送 tags 到远程仓库 git push –tags 推送单个 tag 到远程仓库 git push origin [tagname] 删除远程分支 git push origin –delete [branchName] 远程空分支（等同于删除） git push origin :[branchName] 查看所有分支历史 gitk –all 按日期排序显示历史 gitk –date-order Q&amp;amp;A如何解决gitk中文乱码，git ls-files 中文文件名乱码问题？在~/.gitconfig中添加如下内容[core] quotepath = false[gui] encoding = utf-8[i18n] commitencoding = utf-8[svn] pathnameencoding = utf-8参考 http://zengrong.net/post/1249.htm如何处理本地有更改需要从服务器合入新代码的情况？git stashgit pullgit stash popstash查看 stash 列表：git stash list查看某一次 stash 的改动文件列表（不传最后一个参数默认显示最近一次）：git stash show &quot;stash@{0}&quot;以 patch 方式显示改动内容git stash show -p &quot;stash@{0}&quot;应用某次 stash 改动内容：git stash apply &quot;stash@{0}&quot;如何合并 fork 的仓库的上游更新？git remote add upstream https://upstream-repo-urlgit fetch upstreamgit merge upstream/master如何通过 TortoiseSVN 带的 TortoiseMerge.exe 处理 git 产生的 conflict？ 将 TortoiseMerge.exe 所在路径添加到 path 环境变量。 运行命令 git config --global merge.tool tortoisemerge 将 TortoiseMerge.exe 设置为默认的 merge tool。 在产生 conflict 的目录运行 git mergetool，TortoiseMerge.exe 会跳出来供你 resolve conflict。 也可以运行 git mergetool -t vimdiff 使用 -t 参数临时指定一个想要使用的 merge tool。 不想跟踪的文件已经被提交了，如何不再跟踪而保留本地文件？git rm --cached /path/to/file，然后正常 add 和 commit 即可。如何不建立一个没有 parent 的 branch？git checkout --orphan newbranch此时 git branch 是不会显示该 branch 的，直到你做完更改首次 commit。比如你可能会想建立一个空的 gh-pages branch，那么：git checkout --orphan gh-pagesgit rm -rf .// add your gh-pages branch filesgit add .git commit -m &quot;init commit&quot;submodule 的常用命令添加 submodulegit submodule add git@github.com:philsquared/Catch.git Catch这会在仓库根目录下生成如下 .gitmodules 文件并 clone 该 submodule 到本地。[submodule &quot;Catch&quot;]path = Catchurl = git@github.com:philsquared/Catch.git更新 submodulegit submodule update当 submodule 的 remote 有更新的时候，需要git submodule update --remote当在本地拉取了 submodule 的远程更新，但是想反悔时：git submodule update --init删除 submodule在 .gitmodules 中删除对应 submodule 的信息，然后使用如下命令删除子模块所有文件：git rm --cached Catchclone 仓库时拉取 submodulegit submodule update --init --recursive删除远程 taggit push origin --delete tag [tagname]基于某次 commit 创建 taggit tag &amp;lt;tag name&amp;gt; &amp;lt;commit id&amp;gt;git tag v1.0.0 ef0120清除未跟踪文件git clean可选项： 选项 含义 -q, –quiet 不显示删除文件名称 -n, –dry-run 试运行 -f, –force 强制删除 -i, –interactive 交互式删除 -d 删除文件夹 -e, –exclude 忽略符合 的文件 -x 清除包括 .gitignore 里忽略的文件 -X 只清除 .gitignore 里忽略的文件 忽略文件属性更改因为临时需求对某个文件 chmod 了一下，结果这个就被记为了更改，有时候这是想要的，有时候这会造成困扰。git config --global core.filemode false参考：How do I make Git ignore file mode (chmod) changes?忽略除某后缀名以外的所有文件忽略除了 .c 后缀名以外的所有文件。*!*.c!*/gitignore 里，*、?、[] 可用作通配符。patch将未添加到暂存区的更改生成 patch 文件：git diff &amp;gt; demo.patch将已添加到暂存区的更改生成 patch 文件：git diff --cached &amp;gt; demo.patch合并上面两条命令生成的 patch 文件包含的更改：git apply demo.patch将从 HEAD 之前的 3 次 commit 生成 3 个 patch 文件：（HEAD 可以换成 sha1 码）git format-patch -3 HEAD生成 af8e2 与 eaf8e 之间的 commits 的 patch 文件：（注意 af8e2 比 eaf8e 早）git format-patch af8e2..eaf8e合并 format-patch 命令生成的 patch 文件：git am 0001-Update.patch与 git apply 不同，这会直接 add 和 commit。只下载最新代码git clone --depth 1 git://xxxxxx这样 clone 出来的仓库会是一个 shallow 的状态，要让它变成一个完整的版本：git fetch --unshallow或git pull --unshallow基于某次 commit 创建分支git checkout -b test 5234ab表示以 commit hash 为 5234ab 的代码为基础创建分支 test。恢复单个文件到指定版本git reset 5234ab MainActivity.java恢复 MainActivity.java 文件到 commit hash 为 5234ab 时的状态。设置全局 hooksgit config --global core.hooksPath C:/Users/mazhuang/git-hooks然后把对应的 hooks 文件放在最后一个参数指定的目录即可。比如想要设置在 commit 之前如果检测到没有从服务器同步则不允许 commit，那在以上目录下建立文件 pre-commit，内容如下：#!/bin/shCURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)git fetch origin $CURRENT_BRANCHHEAD=$(git rev-parse HEAD)FETCH_HEAD=$(git rev-parse FETCH_HEAD)if [ &quot;$FETCH_HEAD&quot; = &quot;$HEAD&quot; ];then echo &quot;Pre-commit check passed&quot; exit 0fiecho &quot;Error: you need to update from remote first&quot;exit 1查看某次 commit 的修改内容git show &amp;lt;commit-hash-id&amp;gt;查看某个文件的修改历史git log -p &amp;lt;filename&amp;gt;查看最近两次的修改内容git log -p -2应用已存在的某次更改 / merge 某一个 commitgit cherry-pick &amp;lt;commit-hash-id&amp;gt;cherry-pick 有更多详细的用法，可以参见帮助文档。命令行自动补全在 shell 里加载 git-completion 系列脚本，详见 https://github.com/git/git/tree/master/contrib/completion文件每一行变更明细git blame &amp;lt;filename&amp;gt;找回曾经的历史git reflog列出 HEAD 曾指向过的一系列 commit，它们只存在于本机，不是版本仓库的一部分。还有：git fsck记住 http(s) 方式的用户名密码在有些情况下无法使用 git 协议，比如公司的 git 服务器设置了 IP 白名单，只能在公司内网使用 ssh，那么在外面就只能使用 http(s) 上传下载源码了，但每次都手动输入用户名/密码特别惨，于是乎就记住吧。设置记住密码（默认 15 分钟）：git config --global credential.helper cache自定义记住的时间（如下面是一小时）：git config credential.helper &#39;cache --timeout=3600&#39;长期存储密码：git config --global credential.helper storegit commit 使用 vim 编辑 commit message 中文乱码这个问题在 Windows 下出现了，没找到能完美解决的办法，一种方法是在 vim 打开后输入：:set termencoding=GBK这就有点太麻烦了，折衷的方法是改为使用 gVim 或其它你喜欢的编辑器来编辑 commit message：git config --global core.editor gvim参考： How do I make Git use the editor of my choice for commits? 转：git windows中文 乱码问题解决汇总另外在升级 Vim 到 8.1 之后，由于 PATH 环境变量里加的还是 vim80 文件夹，导致 git commit 时提示：error: cannot spawn gvim: No such file or directoryerror: unable to start editor &#39;gvim&#39;Please supply the message using either -m or -F option.使用 which gvim 查看：$ which gvim/usr/bin/which: no gvim in xxxxxxx将 PATH 里添加的 vim80 路径改为 vim81 后解决。git log 中文乱码只在 Windows 下遇到。git config --global i18n.logoutputencoding gbk编辑 git 安装目录下 etc/profile 文件，在最后添加如下内容：export LESSCHARSET=utf-8参考：Git for windows 中文乱码解决方案git diff 中文乱码只在 Windows 下遇到，目前尚未找到有效办法。统计代码行数CMD 下直接执行可能失败，可以在右键，Git Bash here 里执行。统计某人的代码提交量git log --author=&quot;$(git config --get user.name)&quot; --pretty=tformat: --numstat | gawk &#39;{ add += $1 ; subs += $2 ; loc += $1 - $2 } END { printf &quot;added lines: %s removed lines : %s total lines: %s\\n&quot;,add,subs,loc }&#39;仓库提交者排名前 5如果看全部，去掉 head 管道即可。git log --pretty=&#39;%aN&#39; | sort | uniq -c | sort -k1 -n -r | head -n 5仓库提交者（邮箱）排名前 5这个统计可能不太准，可能有同名。git log --pretty=format:%ae | gawk -- &#39;{ ++c[$0]; } END { for(cc in c) printf &quot;%5d %s\\n&quot;,c[cc],cc; }&#39; | sort -u -n -r | head -n 5贡献者排名git log --pretty=&#39;%aN&#39; | sort -u | wc -l提交数统计git log --oneline | wc -l参考：Git代码行统计命令集修改文件名时的大小写问题修改文件名大小写时，默认会被忽略（在 Windows 下是这样），让 git 对大小写敏感的方法：git config --global core.ignorecase false或者使用 git mv oldname newname 也是可以的。修复 gitk 在 macOS 下显示模糊的问题gitk 很方便，但是在 Mac 系统下默认显示很模糊，影响体验。根据网上搜索的结果，解决方法有两种，我采用第一种解决，第二种未尝试。方法一： 重新启动机器，按 command + R 等 Logo 和进度条出现，会进入 Recovery 模式，选择顶部的实用工具——终端，运行以下命令： csrutil disable 重新启动机器。 编辑 Wish 程序的 plist，启动高分辨率屏支持。 sudo gvim /System/Library/Frameworks/Tk.framework/Versions/Current/Resources/Wish.app/Contents/Info.plist 在最后的 &amp;lt;/dict&amp;gt; 前面加上以下代码 &amp;lt;key&amp;gt;NSHighResolutionCapable&amp;lt;/key&amp;gt; &amp;lt;true/&amp;gt; 更新 Wish.app。 sudo touch Wish.app 再次用 1 步骤的方法进入 Recovery 模式，执行 csrutil enable 启动对系统文件保护，再重启即可。 参考：Mac 中解决 gitk 模糊问题方法二：brew cask install retinizeropen /System/Library/Frameworks/Tk.framework/Versions/Current/Resources/打开 retinizer，将 Wish.app 拖到 retinizer 的界面。参考：起底Git-Git基础clone 时指定 master 以外的分支git clone -b &amp;lt;branch name&amp;gt; --single-branch &amp;lt;repo address&amp;gt;获取当前分支名称git symbolic-ref --short -q HEAD解决 no man viewer handled the request运行命令 git stash --help 报错：warning: failed to exec &#39;man&#39;: Invalid argumentfatal: no man viewer handled the request原因是 Windows 下没有 man 命令。可以修改 git 配置让命令的帮助文档通过浏览器打开。git config --global help.format web比较两个分支的差异显示出所有差异详情：git diff &amp;lt;branch_name_1&amp;gt; &amp;lt;branch_name_2&amp;gt;显示有差异的文件列表：git diff &amp;lt;branch_name_1&amp;gt; &amp;lt;branch_name_2&amp;gt; --stat显示指定文件的差异详情：git diff &amp;lt;branch_name_1&amp;gt; &amp;lt;branch_name_2&amp;gt; &amp;lt;filename&amp;gt;查看 A 分支有，B 分支没有的提交：git log &amp;lt;branch_name_A&amp;gt; ^&amp;lt;branch_name_B&amp;gt;git 操作时报警告警告信息：@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: POSSIBLE DNS SPOOFING DETECTED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@The ECDSA host key for gitlab.xxxx.com has changed,and the key for the corresponding IP address 121.40.151.8is unknown. This could either mean thatDNS SPOOFING is happening or the IP address for the hostand its host key have changed at the same time.@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the ECDSA key sent by the remote host isSHA256:bud2tDwxl9687vMOUUBGXlwZhjxDTu7eVF43ojAu1Pw.Please contact your system administrator.Add correct host key in /c/Users/mzlogin/.ssh/known_hosts to get rid of this message.Offending ECDSA key in /c/Users/mzlogin/.ssh/known_hosts:1ECDSA host key for gitlab.xxxx.com has changed and you have requested strict checking.Host key verification failed.fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists.解决方案：rm ~/.ssh/known_hosts然后重新操作即可。删除不存在对应远程分支的本地分支（本小节有效性存疑，有时候并不好使。）$ git remote show origindevelop trackedmaster trackedfeature/new-ui trackedrefs/remotes/origin/feature/test stale (use &#39;git remote prune&#39; to remove)...其中 feature/test 就是不存在远程分支的本地分支。$ git remote prune origin清除完成。" } ]
